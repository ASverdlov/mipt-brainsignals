\documentclass[12pt,twoside]{article}
\usepackage{jmlda}

\newcommand{\bff}{\mathbf{f}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bTheta}{\boldsymbol{\Theta}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bbb}{\mathbf{b}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\Sim}{\textrm{Sim}}
\newcommand{\Rel}{\textrm{Rel}}
\newcommand{\cov}{\textrm{cov}}
\newcommand{\var}{\textrm{var}}

\begin{document}
%\NOREVIEWERNOTES
\title
    {Прогнозирование намерений по cигналам мозга ECoG}
\author
    {Калиниченко~О.\,И., Ремизова~А.\,С.} % основной список авторов, выводимый в оглавление
\thanks
{	Научный руководитель:  Стрижов~В.\,В. 
	Задачу поставил:  Стрижов~В.\,В.
	Консультант:  Исаченко~Р.\,В.}
% \email{author@site.ru}
\organization
{$^1$ Московский физико-технический институт}
\abstract
{Работа посвящена построению системы тестирования прогностических моделей.
	Рассматривается случай коррелированных входных сигналов высокой размерности.
	В качестве прикладной задачи рассматривается задача предсказания намерений по сигналам головного мозга.
	Входные данные -- сигналы электрокортикограммы (ECoG).
	Для выявления и устранения скрытых зависимостей используются методы снижения размерности пространства и отбора признаков.
	Предложенная система тестирования оценивает качество прогноза моделей и проводит анализ ошибки.
	Вычислительный эксперимент проводится на реальных данных ECoG.
	
	\bigskip
	\textbf{Ключевые слова}: \emph {декодирование временных рядов, PLS, QPFS}.}

\maketitle

\section{Введение}
Работа посвящена исследованию методов моделирования нейросетевого интерфейса (BCI) \cite{Motrenko17ECoG}.
Входные данные -- сигналы мозга, полученные с помощью электрокортикографии (ECoG) и электроэнцефалографии (EEG). ECoG-сигналы имеют лучшее разрешение и большую амплитуду, однако для их получения требуется непосредственное подсоединение электродов к коре головного мозга. Одной из задач при построении систем BCI является предсказание намерений.

Предлагается декодировать исходные сигналы и спрогнозировать траекторию движения верхних конечностей. Исходное пространство имеет избыточно высокую размерность. Линейная зависимость между признаками приводит к мультиколлинеарности. Для устранения мультиколлинеарности предлагается применить методы понижения размерности и отбора признаков.

Признаковое описание многомерного временного ряда существует в пространствах независимых и зависимых переменных. Для учета существующих закономерностей в исходном и выходном пространстве используется скрытое пространство латентных переменных.  В скрытом пространстве происходит согласование между образами исходных пространств.

В эксперименте рассматриваются следующие модели: метод частных наименьших квадратов (PLS) \cite{Isachenko17PLS}, отбор признаков с помощью квадратичного программирования (QPFS) \cite{Katrutsa16QPFS}, метод Белсли (Belsley) и вариации этих методов.
% Нелинейные модели -- нейросети.

PLS является методом отбора признаков

Описание метода QPFS...

Предлагается система тестирования прогностических моделей с оценкой качества и анализом ошибки. Подобный инструмент может применяться не только в задаче анализа сигналов мозга, но и во многих других задачах, связанных с прогнозированием многомерных временных рядов.

\section{Постановка задачи}
\paragraph{Постановка задачи предсказания}

Задана выборка $\mathfrak{D}= \left( \bX, \bY \right)$, где $\bX \in \RR^{m \times n}$ --- матрица объектов, $\bY \in \RR^{m \times r}$ --- матрица ответов. Имеется некоторая модель $\bff$ с набором параметров $\btheta$ из пространства $\Theta$, предсказывающая
$\by \in \RR^r$ по $\bx \in \RR^n$. 

Определяется функция ошибки $S$ на выборке $\mathfrak{D}$  и модели $\bff$ с параметрами $\btheta$. Задачей является поиск наилучших параметров $\btheta^*$, то есть таких, при которых функция ошибки минимальна:
\begin{equation}
\btheta^* = \arg \min_{\btheta \in \Theta} S(\btheta| \mathfrak{D}, \bff).
\label{eq::error_function}
\end{equation}

Однако в случае кореллированных данных $\bX$ задача может оказаться нестабильной.  Одним из таких случаев является и широко распространенный класс линейных моделей:
\begin{equation}
	\bff(\bx, \btheta) = \underset{1 \times n}{\bx} \cdot \underset{n \times r}{\btheta}.
	\label{eq::linear_model}
\end{equation}

За $\bff(\bX, \btheta)$ обозначена матрица $\left[\bff(\bx_1, \btheta), \bff(\bx_2, \btheta), \dots, \bff(\bx_m, \btheta)\right]\T$. Рассматривается квадратичная функция ошибки:
\begin{equation}
	{\bigl\| \bff(\bX, \btheta) - \bY \bigr\| }_2^2 
	\rightarrow \min_{\btheta \in \Theta} 
	\label{eq::error_linear}
\end{equation}
Если пространство признаков имеет высокую размерность, вероятно, что матрица $\bX$ близка к вырожденной, а потому решение проблемы оптимизации \eqref{eq::error_linear} будет нестабильным. Поэтому для решения указанной задачи применяются методы отбора признаков, такие как PLS и QPFS.

\paragraph{PLS.}
Метод частных наименьших квадратов PLS рассматривает в качестве признаков линейные комбинации исходных. Предполагается, что существует скрытое пространство латентных переменных малой размерности $l$ ($l < n, r$). Происходит поиск матрицы $\bT \in \RR^{m \times l}$, которая наилучшим образом описывает матрицы $\bX$ и $\bY$. 

\begin{align}
	\underset{m \times n}{\bX} &= \underset{m \times l}{\bT\T} \cdot
	\underset{l \times n}{\bP\T} + \underset{m \times n}{\bE}
	\label{eq::PLS_X} \\
	\underset{m \times r}{\bY} &= \underset{m \times l}{\bU\T} \cdot
	% \underset{l \times l}{\textrm{diag}(\bbeta)}\cdot
	\underset{l \times r}{\bQ\T} + \underset{m \times r}{\bF}
	\label{eq::PLS_Y}
\end{align}

$\bT$ ---

\paragraph{QPFS} Сформулируем задачу отбора признаков.  

Чтобы вычислить матрицу $\bQ$ и вектор $\bbb$

\begin{align}
\Sim & \label{eq::Sim} \\
\Rel & \label{eq::Rel}
\end{align}

Коэффициент корреляции Пирсона определяется как:

$$\rho_{ij} =\frac{
\cov(\bx_i, \bx_j)
}{
\sqrt{\var(\bx_i) \cdot \var(\bx_j)}
} $$


\paragraph{Метрики}

Пусть имеются истинный прогноз $\bY = (\by_1, \by_2, \dots, \by_m)$ и предсказание $\mathbf{\hat{Y}} = (\mathbf{\hat{y}}_1, \mathbf{\hat{y}}_2, \dots, \mathbf{\hat{y}}_m)$; $\by_i$ и $\mathbf{\hat{y}}_i$, $i = 1, 2, \dots, m$ -- вектора размерности $r$.

Среднеквадратичная  ошибка (mean squared error):

\begin{equation}
	\text{MSE}(\bY, \mathbf{\hat{Y}}) =
	\frac{1}{m}
	\sum^m_{i=1}
	{\bigl\| \mathbf{y}_i - \mathbf{\hat{y}}_i \bigr\| }_2^2 
	\label{eq::error_mse}
\end{equation}

Корень среднеквадратичной ошибки (root-mean-squared error):

\begin{equation}
\text{RMSE}(\bY, \mathbf{\hat{Y}}) =
\sqrt{\text{MSE}(\bY, \mathbf{\hat{Y}})}
\label{eq::error_rmse}
\end{equation}

Нормированная среднеквадратичная ошибка (scaled mean squared error):

\begin{equation}
\text{sMSE}(\bY, \mathbf{\hat{Y}}) =
\frac{
\sum^m_{i=1}
{\bigl\| \mathbf{y}_i - \mathbf{\hat{y}}_i \bigr\| }_2^2 
}{
\sum^m_{i=1}
{\bigl\| \mathbf{y}_i - \mathbf{\overline{y}} \bigr\| }_2^2 
}, \;
\mathbf{\overline{y}} = \frac{1}{m} \sum_{i=1}^{m} y_i
\label{eq::error_smse}
\end{equation}


MAE, MADE, Коэффициент корреляции. Различные параметры модели из \cite{Katrutsa16QPFS}.


\begin{thebibliography}{1}
\bibitem{bci}
    \BibAuthor{
    	J. del R.\; Mill?n,
    	F. \; Renken,
    	J. \; Mouri?o and
    	W. \; Gerstner}
    \BibTitle{Brain-actuated interaction}~//
    \BibJournal{Artif. Intell.}, 159(2004) 241–259.
\bibitem{Isachenko17PLS}
    \BibAuthor{
    	Isachenko \; R.,
    	Vladimirova \; M.,
    	Strijov \; V.}
    \BibTitle{Dimensionality reduction for time series decoding and
    	forecasting problems}~//
    \BibJournal{Machine Learning and Data Analysis}.
\bibitem{Katrutsa16QPFS}
    \BibAuthor{
    	Katrutsa \; A.,
    	Strijov \; V.}
    \BibTitle{Comprehensive study of feature selection methods to solve
    	multicollinearity problem according to evaluation criteria}~//
    \BibJournal{Expert System with Applications}, 76, 1-11.
\bibitem{Motrenko17ECoG}
	\BibAuthor{
		Motrenko \; A.,
		Strijov \; V.}
	\BibTitle{Multi-way Feature Selection for ECoG-based Brain-Computer
	Interface}~//
	\BibJournal{???}.

\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
