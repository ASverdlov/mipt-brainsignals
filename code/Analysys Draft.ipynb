{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run \"./metrics/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Bootstrap():\n",
    "    def __init__(self, X, y, n_samples, len_sample):\n",
    "        self.n_samples = n_samples\n",
    "        self.len_sample = len_sample\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.sample_X = np.zeros((n_samples, len_sample, self.X.shape[1]))\n",
    "        self.sample_y = np.zeros((n_samples, len_sample, self.y.shape[1]))\n",
    "        for i in range(n_samples):\n",
    "            idx = np.random.choice(np.arange(len(X)), len_sample, replace=True)\n",
    "            self.sample_X[i] = self.X[idx]\n",
    "            self.sample_y[i] = self.y[idx]\n",
    "        #print('a', *self.sample_X)\n",
    "        #print('b', *self.sample_y)\n",
    "    \n",
    "    def values(self):\n",
    "        return self.sample_X, self.sample_y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "b = Bootstrap(X, X, 5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    def predict_params(self, X):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"./metrics/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FunctionEvaluator():\n",
    "    def __init__(self, func=None):\n",
    "        if func == None:\n",
    "            self.function = lambda a, b: 0\n",
    "        else:\n",
    "            self.function = func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Metric(FunctionEvaluator):\n",
    "    def evaluate(self, model, X, y):\n",
    "        z = self.function(y, model.predict(X))\n",
    "        return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Characteristic(FunctionEvaluator):\n",
    "    def evaluate(self, model):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Comparison(FunctionEvaluator):\n",
    "    def evaluate(self, full_model, model, full_X, y, mask):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RSS(Metric):\n",
    "    def __init__(self):\n",
    "        super(RSS, self).__init__(residual_square_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Adjusted_Determination_Coefficient(Metric):\n",
    "    def __init__(self):\n",
    "        super(Adjusted_Determination_Coefficient, self).__init__(determination_coefficient)\n",
    "        \n",
    "class Determination_Coefficient(Metric):\n",
    "    def __init__(self):\n",
    "        super(Determination_Coefficient, self).__init__(determination_coefficient)\n",
    "    def evaluate(self, model, X, y):\n",
    "        z = self.function(y, model.predict(X), False)\n",
    "        #print(\"Z\", z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VIF(Metric):\n",
    "    def __init__(self):\n",
    "        super(VIF, self).__init__(variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BIC(Metric):\n",
    "    def __init__(self):\n",
    "        super(BIC, self).__init__(bayesian_information_criterion)\n",
    "    def evaluate(self, model, X, y):\n",
    "        num_features = X.shape[1]\n",
    "        z = self.function(y, model.predict(X), num_features)\n",
    "        #print(\"Z\", z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Cp(Comparison):\n",
    "    def __init__(self):\n",
    "        super(Cp, self).__init__(mallows_Cp)\n",
    "    def evaluate(self, full_model, model, full_X, y, mask):\n",
    "        y_full = full_model.predict(full_X)\n",
    "        y_p = model.predict((full_X.T[mask]).T)\n",
    "        p = mask.sum()\n",
    "        z = self.function(y, y_full, y_p, p)\n",
    "        #print(*mask)\n",
    "        #print(*full_model.coef_)\n",
    "        #print(*model.coef_)\n",
    "        #print(\"A\", y_full, y_p, z)\n",
    "        return z\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Condition_Number(Characteristic):\n",
    "    def __init__(self):\n",
    "        super(Condition_Number, self).__init__(condition_number_xtx)\n",
    "    def evaluate(self, model):\n",
    "        X = model.coef_\n",
    "        return self.function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.913870044034976"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Condition_Number()\n",
    "c.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EvaluateInfo():\n",
    "    def __init__(self, model, metrics = [], characteristics = [], comparisons = []):\n",
    "        self.model = model\n",
    "        self.characteristics = characteristics # characteristic of the fitted model itself\n",
    "        self.metrics = metrics # compares y and y_pred\n",
    "        self.comparisons = comparisons #compares y, y_pred, y_pred_with_reduced_features\n",
    "        #self.mode = mode\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test, y_test, mask = None, n_samples=20, len_sample=None):\n",
    "        if mask is None:\n",
    "            mask = np.ones(X.shape[1], dtype=np.bool)\n",
    "        #print(\"MASK\", mask)\n",
    "        self.mask = np.array(mask, dtype=bool)\n",
    "        if len_sample is None:\n",
    "            len_sample = X.shape[1]\n",
    "        self.len_sample = len_sample\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.full = deepcopy(self.model.fit(self.X_train, self.y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class EvaluateStaticInfo(EvaluateInfo):\n",
    "    def __init__(self, model, metrics = [], comparisons = []):\n",
    "        super(EvaluateStaticInfo, self).__init__(model, metrics, [], comparisons)\n",
    "    \n",
    "    def __eval(self, b):\n",
    "        model = self.model\n",
    "        \n",
    "        sample_X, sample_y = b.values()\n",
    "        result_metrics = np.zeros((len(self.metrics), self.n_samples))\n",
    "        result_comparisons = np.zeros((len(self.comparisons), self.n_samples))\n",
    "        \n",
    "        model.fit((self.X_train.T[self.mask]).T, self.y_train)\n",
    "        \n",
    "        for it in range(self.n_samples):\n",
    "            for (i, metric) in enumerate(self.metrics):\n",
    "                result_metrics[i][it] = metric.evaluate(model, (sample_X[it].T[self.mask]).T, sample_y[it])\n",
    "            for(i, comp) in enumerate(self.comparisons):\n",
    "                result_comparisons[i][it] = comp.evaluate(self.full, model, sample_X[it], sample_y[it], self.mask)\n",
    "                \n",
    "        return result_metrics, result_comparisons\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, mask = None, n_samples=20, len_sample=None):\n",
    "        #self.b_train = Bootstrap(self.X_train, self.y_train, self.n_samples, self.len_sample)\n",
    "        super(EvaluateStaticInfo, self).fit(X_train, y_train, X_test, y_test, mask, n_samples, len_sample)\n",
    "        self.b = Bootstrap(self.X_test, self.y_test, self.n_samples, self.len_sample)\n",
    "        return (self.__eval(self.b))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class EvaluateStaticInfo(EvaluateInfo):\n",
    "    def __init__(self, model, metrics = [], comparisons = []):\n",
    "        super(EvaluateStaticInfo, self).__init__(model, metrics, [], comparisons)\n",
    "    \n",
    "    def __eval(self, b):\n",
    "        model = self.model\n",
    "        \n",
    "        sample_X, sample_y = b.values()\n",
    "        result_metrics = np.zeros((len(self.metrics), self.n_samples))\n",
    "        result_comparisons = np.zeros((len(self.comparisons), self.n_samples))\n",
    "        \n",
    "        model.fit((self.X_train.T[self.mask]).T, self.y_train)\n",
    "        \n",
    "        for it in range(self.n_samples):\n",
    "            for (i, metric) in enumerate(self.metrics):\n",
    "                result_metrics[i][it] = metric.evaluate(model, (sample_X[it].T[self.mask]).T, sample_y[it])\n",
    "            for(i, comp) in enumerate(self.comparisons):\n",
    "                result_comparisons[i][it] = comp.evaluate(self.full, model, sample_X[it], sample_y[it], self.mask)\n",
    "                \n",
    "        return result_metrics, result_comparisons\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, mask = None, n_samples=20, len_sample=None):\n",
    "        #self.b_train = Bootstrap(self.X_train, self.y_train, self.n_samples, self.len_sample)\n",
    "        super(EvaluateStaticInfo, self).fit(X_train, y_train, X_test, y_test, mask, n_samples, len_sample)\n",
    "        self.b = Bootstrap(self.X_test, self.y_test, self.n_samples, self.len_sample)\n",
    "        return (self.__eval(self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mo = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sps\n",
    "\n",
    "XX = sps.norm.rvs(size=(10, 5))\n",
    "X2 = sps.norm.rvs(size=(10, 5))\n",
    "zz = sps.uniform.rvs(size=(5, 3))\n",
    "yy = XX @ zz + sps.norm.rvs(scale=0.1, size=(10, 3))\n",
    "y2 = X2 @ zz + sps.norm.rvs(scale=0.1, size=(10, 3))\n",
    "maskk = np.ones(XX.shape[1])\n",
    "maskk[2]=0\n",
    "maskk[1] = 0\n",
    "maskk[3] = 0\n",
    "print(maskk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric1 = RSS()\n",
    "metric2 = Adjusted_Determination_Coefficient()\n",
    "metric3 = Determination_Coefficient()\n",
    "metric4 = VIF()\n",
    "metric5 = BIC()\n",
    "comp1 = Cp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = EvaluateStaticInfo(model=mo, metrics = [], comparisons=[comp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], shape=(0, 20), dtype=float64),\n",
       " array([[  56.77635917,   11.20013717,   43.16441014,    5.27139937,\n",
       "          108.07203138,  198.31122074,  126.02825798,  183.80257228,\n",
       "           58.63601802,   44.87887878,   61.79998661,  161.0235449 ,\n",
       "           55.7222075 ,   36.30970869,   57.03498073,   80.04724727,\n",
       "           32.63343492,  117.85588343,   39.83289258,  162.69393357]]))"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.fit(XX, yy, X2, y2, mask=maskk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
