{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run \"./metrics/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Bootstrap():\n",
    "    def __init__(self, X, y, n_samples, len_sample):\n",
    "        self.n_samples = n_samples\n",
    "        self.len_sample = len_sample\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.sample_X = np.zeros((n_samples, len_sample, self.X.shape[1]))\n",
    "        self.sample_y = np.zeros((n_samples, len_sample, self.y.shape[1]))\n",
    "        for i in range(n_samples):\n",
    "            idx = np.random.choice(np.arange(len(X)), len_sample, replace=True)\n",
    "            self.sample_X[i] = self.X[idx]\n",
    "            self.sample_y[i] = self.y[idx]\n",
    "        #print('a', *self.sample_X)\n",
    "        #print('b', *self.sample_y)\n",
    "    \n",
    "    def values(self):\n",
    "        return self.sample_X, self.sample_y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "b = Bootstrap(X, X, 5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    def predict_params(self, X):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%run \"./metrics/metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FunctionEvaluator():\n",
    "    def __init__(self, func=None):\n",
    "        if func == None:\n",
    "            self.function = lambda a, b: 0\n",
    "        else:\n",
    "            self.function = func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Metric(FunctionEvaluator):\n",
    "    def evaluate(self, model, X, y):\n",
    "        z = self.function(y, model.predict(X))\n",
    "        return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Characteristic(FunctionEvaluator):\n",
    "    def evaluate(self, model):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Comparison(FunctionEvaluator):\n",
    "    def evaluate(self, full_model, model, full_X, y, mask):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class RSS(Metric):\n",
    "    def __init__(self):\n",
    "        super(RSS, self).__init__(residual_square_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Adjusted_Determination_Coefficient(Metric):\n",
    "    def __init__(self):\n",
    "        super(Adjusted_Determination_Coefficient, self).__init__(determination_coefficient)\n",
    "        \n",
    "class Determination_Coefficient(Metric):\n",
    "    def __init__(self):\n",
    "        super(Determination_Coefficient, self).__init__(determination_coefficient)\n",
    "    def evaluate(self, model, X, y):\n",
    "        z = self.function(y, model.predict(X), False)\n",
    "        #print(\"Z\", z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class VIF(Metric):\n",
    "    def __init__(self):\n",
    "        super(VIF, self).__init__(variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BIC(Metric):\n",
    "    def __init__(self):\n",
    "        super(BIC, self).__init__(bayesian_information_criterion)\n",
    "    def evaluate(self, model, X, y):\n",
    "        num_features = X.shape[1]\n",
    "        z = self.function(y, model.predict(X), num_features)\n",
    "        #print(\"Z\", z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Cp(Comparison):\n",
    "    def __init__(self):\n",
    "        super(Cp, self).__init__(mallows_Cp)\n",
    "    def evaluate(self, full_model, model, full_X, reduced_X, y):\n",
    "        y_full = full_model.predict(full_X)\n",
    "        y_p = model.predict(reduced_X)\n",
    "        p = reduced_X.shape[1]\n",
    "        z = self.function(y, y_full, y_p, p)\n",
    "        #print(*mask)\n",
    "        #print(*full_model.coef_)\n",
    "        #print(*model.coef_)\n",
    "        #print(\"A\", y_full, y_p, z)\n",
    "        return z\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Condition_Number(Characteristic):\n",
    "    def __init__(self):\n",
    "        super(Condition_Number, self).__init__(condition_number_xtx)\n",
    "    def evaluate(self, model):\n",
    "        X = model.coef_\n",
    "        return self.function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5466285ad8ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondition_Number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "c = Condition_Number()\n",
    "c.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class EvaluateInfo():\n",
    "    def __init__(self, model, metrics = [], comparisons = [], characteristics = []):\n",
    "        self.model = model\n",
    "        self.characteristics = characteristics # characteristic of the fitted model itself\n",
    "        self.metrics = metrics # compares y and y_pred\n",
    "        self.comparisons = comparisons #compares y, y_pred, y_pred_with_reduced_features\n",
    "        \n",
    "    def fit(self, X_train, y_train, X_test, y_test, masks = None, n_samples=20, len_sample=None):\n",
    "        if masks is None:\n",
    "            masks = np.ones((1, X.shape[1]), dtype=bool)\n",
    "        masks = np.array(masks, dtype=bool)\n",
    "        if len(masks.shape) == 1:\n",
    "            masks = masks.reshape((1, len(masks.shape)))\n",
    "        self.masks = masks\n",
    "        \n",
    "        if len_sample is None:\n",
    "            len_sample = X_train.shape[1]\n",
    "        self.len_sample = len_sample\n",
    "        \n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.full = deepcopy(self.model.fit(self.X_train, self.y_train))\n",
    "        \n",
    "        self.result_metrics = np.zeros((len(self.metrics), len(self.masks), self.n_samples))\n",
    "        self.result_comparisons = np.zeros((len(self.comparisons), len(self.masks), self.n_samples))\n",
    "        \n",
    "    def returnMetrics(self):\n",
    "        return self.result_metrics\n",
    "    def returnComparisons(self):\n",
    "        return self.result_comparisons\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class EvaluateStaticInfo(EvaluateInfo):\n",
    "    def __init__(self, model, metrics = [], comparisons = []):\n",
    "        super(EvaluateStaticInfo, self).__init__(model, metrics, comparisons, [])\n",
    "    \n",
    "    def __eval(self):\n",
    "        model = self.model\n",
    "        \n",
    "        sample_X, sample_y = self.boot.values()\n",
    "        \n",
    "        self.models = []\n",
    "        for mask in self.masks:\n",
    "            self.models += [deepcopy(model.fit((self.X_train.T[mask]).T, self.y_train))]\n",
    "        \n",
    "        for (m, mask) in enumerate(self.masks):\n",
    "            for it in range(self.n_samples):\n",
    "                reduced_X_cur = (sample_X[it].T[mask]).T\n",
    "                for (i, metric) in enumerate(self.metrics):\n",
    "                    self.result_metrics[i][m][it] = metric.evaluate(self.models[m], reduced_X_cur, sample_y[it])\n",
    "                for(i, comp) in enumerate(self.comparisons):\n",
    "                    self.result_comparisons[i][m][it] = comp.evaluate(self.full, self.models[m], sample_X[it], \n",
    "                                                              reduced_X_cur, sample_y[it])\n",
    "                \n",
    "        return result_metrics, result_comparisons\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, masks = None, n_samples=20, len_sample=None):\n",
    "        super(EvaluateStaticInfo, self).fit(X_train, y_train, X_test, y_test, masks, n_samples, len_sample)\n",
    "        self.boot = Bootstrap(self.X_test, self.y_test, self.n_samples, self.len_sample)\n",
    "        self.__eval()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class EvaluateDynamicInfo(EvaluateInfo):\n",
    "    def __init__(self, model, metrics = [], comparisons = [], characteristics = []):\n",
    "        super(EvaluateDynamicInfo, self).__init__(model, metrics, comparisons, characteristics)\n",
    "    \n",
    "    def __eval(self):\n",
    "        model = self.model\n",
    "        \n",
    "        sample_X, sample_y = self.boot.values()\n",
    "        \n",
    "        self.result_characteristics = np.zeros((len(self.characteristics), len(self.masks), self.n_samples))\n",
    "            \n",
    "        for (m, mask) in enumerate(self.masks):\n",
    "            reduced_X_test = (self.X_test.T[mask]).T\n",
    "            for it in range(self.n_samples):\n",
    "                model.fit((sample_X[it].T[mask]).T, sample_y[it])\n",
    "                for (i, metric) in enumerate(self.metrics):\n",
    "                    self.result_metrics[i][m][it] = metric.evaluate(model, reduced_X_test, self.y_test)\n",
    "\n",
    "                for (i, char) in enumerate(self.characteristics):\n",
    "                    self.result_characteristics[i][m][it] = char.evaluate(model)\n",
    "\n",
    "                for (i, comp) in enumerate(self.comparisons):\n",
    "                    self.result_comparisons[i][m][it] = comp.evaluate(self.full, model, self.X_test,\n",
    "                                                              reduced_X_test, self.y_test)\n",
    "                \n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, masks = None, n_samples=20, len_sample=None):\n",
    "        super(EvaluateDynamicInfo, self).fit(X_train, y_train, X_test, y_test, masks, n_samples, len_sample)\n",
    "        self.boot = Bootstrap(self.X_test, self.y_test, self.n_samples, self.len_sample)\n",
    "        self.__eval()\n",
    "    \n",
    "    def returnCharacteristics(self):\n",
    "        return self.result_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "mo = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sps\n",
    "\n",
    "XX = sps.norm.rvs(size=(10, 5))\n",
    "X2 = sps.norm.rvs(size=(10, 5))\n",
    "zz = sps.uniform.rvs(size=(5, 3))\n",
    "yy = XX @ zz + sps.norm.rvs(scale=0.1, size=(10, 3))\n",
    "y2 = X2 @ zz + sps.norm.rvs(scale=0.1, size=(10, 3))\n",
    "maskk = np.ones(XX.shape[1])\n",
    "maskk[2]=0\n",
    "maskk[1] = 0\n",
    "maskk[3] = 0\n",
    "print(maskk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metric1 = RSS()\n",
    "metric2 = Adjusted_Determination_Coefficient()\n",
    "metric3 = Determination_Coefficient()\n",
    "metric4 = VIF()\n",
    "metric5 = BIC()\n",
    "char1 = Condition_Number()\n",
    "comp1 = Cp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "info = EvaluateDynamicInfo(mo, [metric1, metric2, metric3, metric4, metric5],\n",
    "                           [comp1], [char1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "info.fit(XX, yy, X2, y2, masks=[maskk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.99595725e+01,   1.76834590e+03,   3.59855593e+01,\n",
       "           3.16836763e+02,   5.91651541e+01,   5.20435897e+03,\n",
       "           8.14823974e+04,   1.69382504e+01,   3.94164590e+01,\n",
       "           5.81383293e+03,   1.47671362e+04,   3.98990714e+01,\n",
       "           2.90024117e+02,   2.01017844e+04,   2.02453433e+01,\n",
       "           1.80025596e+01,   2.21682228e+01,   3.21612057e+01,\n",
       "           2.06164804e+02,   2.25273143e+01]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.returnComparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
